import random
import copy

# Define the board size
BOARD_SIZE = 8

# Define the initial board state
INITIAL_BOARD = [
    [1, 1, 1, 1, 1, 1, 1, 1],
    [1, 1, 1, 1, 1, 1, 1, 1],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0],
    [2, 2, 2, 2, 2, 2, 2, 2],
    [2, 2, 2, 2, 2, 2, 2, 2]
]

# Define the heuristics
def defensive_heuristic_1(board, player):
    own_pieces = sum(row.count(player) for row in board)
    return 2 * own_pieces + random.random()

def offensive_heuristic_1(board, player):
    opponent = 3 - player
    opponent_pieces = sum(row.count(opponent) for row in board)
    return 2 * (30 - opponent_pieces) + random.random()

# Define the AlphaBetaAgent class
class AlphaBetaAgent:
    def __init__(self, board, player, depth, heuristic):
        self.board = board
        self.player = player
        self.depth = depth
        self.heuristic = heuristic
        self.total_nodes = 0

    def get_possible_moves(self, board, player):
        moves = []
        direction = 1 if player == 1 else -1
        for x in range(BOARD_SIZE):
            for y in range(BOARD_SIZE):
                if board[x][y] == player:
                    if x + direction < BOARD_SIZE and x + direction >= 0:
                        if board[x + direction][y] == 0:
                            moves.append((x, y, x + direction, y))
                        if y - 1 >= 0 and board[x + direction][y - 1] != player:
                            moves.append((x, y, x + direction, y - 1))
                        if y + 1 < BOARD_SIZE and board[x + direction][y + 1] != player:
                            moves.append((x, y, x + direction, y + 1))
        return moves

    def apply_move(self, board, move):
        new_board = copy.deepcopy(board)
        from_x, from_y, to_x, to_y = move
        new_board[to_x][to_y] = new_board[from_x][from_y]
        new_board[from_x][from_y] = 0
        return new_board

    def is_terminal_state(self, board):
        if 1 in board[BOARD_SIZE - 1] or 2 in board[0]:
            return True
        if sum(row.count(1) for row in board) == 0 or sum(row.count(2) for row in board) == 0:
            return True
        return False

    def alpha_beta_search(self, board, depth, alpha, beta, maximizing_player):
        self.total_nodes += 1
        if depth == 0 or self.is_terminal_state(board):
            return self.heuristic(board, self.player), None

        if maximizing_player:
            max_eval = float('-inf')
            best_move = None
            for move in self.get_possible_moves(board, self.player):
                new_board = self.apply_move(board, move)
                eval, _ = self.alpha_beta_search(new_board, depth - 1, alpha, beta, False)
                if eval > max_eval:
                    max_eval = eval
                    best_move = move
                alpha = max(alpha, eval)
                if beta <= alpha:
                    break
            return max_eval, best_move
        else:
            min_eval = float('inf')
            best_move = None
            for move in self.get_possible_moves(board, 3 - self.player):
                new_board = self.apply_move(board, move)
                eval, _ = self.alpha_beta_search(new_board, depth - 1, alpha, beta, True)
                if eval < min_eval:
                    min_eval = eval
                    best_move = move
                beta = min(beta, eval)
                if beta <= alpha:
                    break
            return min_eval, best_move

    def get_best_move(self):
        _, best_move = self.alpha_beta_search(self.board, self.depth, float('-inf'), float('inf'), True)
        return best_move

# Example usage
def main():
    board = copy.deepcopy(INITIAL_BOARD)
    player = 1
    depth = 3
    heuristic = offensive_heuristic_1

    while not AlphaBetaAgent(board, player, depth, heuristic).is_terminal_state(board):
        agent = AlphaBetaAgent(board, player, depth, heuristic)
        move = agent.get_best_move()
        if move:
            board = agent.apply_move(board, move)
            player = 3 - player
        else:
            break

    print("Final board state:")
    for row in board:
        print(row)

if __name__ == "__main__":
    main()
