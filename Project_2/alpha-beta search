
import copy
import random

BOARD_SIZE = 8
PLAYER_1 = 1
PLAYER_2 = 2
EMPTY = 0

def defensive_heuristic_1(board, player):
    own_pieces = sum(row.count(player) for row in board)
    return 2 * own_pieces + random.random()

def offensive_heuristic_1(board, player):
    opponent = PLAYER_2 if player == PLAYER_1 else PLAYER_1
    opponent_pieces = sum(row.count(opponent) for row in board)
    return 2 * (30 - opponent_pieces) + random.random()

class AlphaBetaAgent:
    def __init__(self, board, player, depth, heuristic):
        self.board = board
        self.player = player
        self.depth = depth
        self.heuristic = heuristic
        self.total_nodes = 0

    def get_possible_moves(self, board, player):
        moves = []
        direction = 1 if player == PLAYER_1 else -1
        for x in range(BOARD_SIZE):
            for y in range(BOARD_SIZE):
                if board[x][y] == player:
                    if x + direction < BOARD_SIZE and x + direction >= 0:
                        if board[x + direction][y] == EMPTY:
                            moves.append((x, y, x + direction, y))
                        if y - 1 >= 0 and board[x + direction][y - 1] != player:
                            moves.append((x, y, x + direction, y - 1))
                        if y + 1 < BOARD_SIZE and board[x + direction][y + 1] != player:
                            moves.append((x, y, x + direction, y + 1))
        return moves

    def apply_move(self, board, move):
        new_board = copy.deepcopy(board)
        from_x, from_y, to_x, to_y = move
        new_board[to_x][to_y] = new_board[from_x][from_y]
        new_board[from_x][from_y] = EMPTY
        return new_board

    def is_terminal_state(self, board):
        if 1 in board[BOARD_SIZE - 1] or 2 in board[0]:
            return True
        if sum(row.count(1) for row in board) == 0 or sum(row.count(2) for row in board) == 0:
            return True
        return False

    def alpha_beta_search(self, board, depth, alpha, beta, maximizing_player):
        self.total_nodes += 1
        if depth == 0 or self.is_terminal_state(board):
            return self.heuristic(board, self.player), None

        if maximizing_player:
            max_eval = float('-inf')
            best_move = None
            for move in self.get_possible_moves(board, self.player):
                new_board = self.apply_move(board, move)
                eval, _ = self.alpha_beta_search(new_board, depth - 1, alpha, beta, False)
                if eval > max_eval:
                    max_eval = eval
                    best_move = move
                alpha = max(alpha, eval)
                if beta <= alpha:
                    break
            return max_eval, best_move
        else:
            min_eval = float('inf')
            best_move = None
            for move in self.get_possible_moves(board, 3 - self.player):
                new_board = self.apply_move(board, move)
                eval, _ = self.alpha_beta_search(new_board, depth - 1, alpha, beta, True)
                if eval < min_eval:
                    min_eval = eval
                    best_move = move
                beta = min(beta, eval)
                if beta <= alpha:
                    break
            return min_eval, best_move

    def get_best_move(self):
        _, best_move = self.alpha_beta_search(self.board, self.depth, float('-inf'), float('inf'), True)
        return best_move
