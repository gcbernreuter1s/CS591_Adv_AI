import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler


def load_data(filename):
    data = np.genfromtxt(filename, delimiter='\t', skip_header=1)
    return data[:, 0], data[:, 1]


def compute_features(x):
    return np.vstack([np.ones_like(x), x, x**2, x**3]).T


def predict(X, weights):
    return np.dot(X, weights)


def gradient_descent(X, y, weights, learning_rate, epochs):
    m = len(y)
    history = []
    
    for epoch in range(epochs):
        predictions = predict(X, weights)
        errors = predictions - y
        gradients = np.dot(X.T, errors) / m  
        
    
        weights -= learning_rate * gradients
        
        
        history.append(weights.copy())

        if epoch % 100 == 0 or epoch == epochs - 1:
            plt.plot(X, predict(X, weights), label=f'Epoch {epoch+1}')
    
    return weights, history

def main():
    x, y = load_data('Part1_x_y_Values.txt')
    
    scaler = StandardScaler()
    x_scaled = scaler.fit_transform(x.reshape(-1, 1))
    
    X = compute_features(x_scaled.flatten())
    
    weights = np.random.randn(4) * 0.1
    
    learning_rate = 0.01 
    epochs = 5000 
    
    final_weights, history = gradient_descent(X, y, weights, learning_rate, epochs)
    
    plt.figure(figsize=(10, 6))
    plt.scatter(x, y, color='red', label='Data points')
    
    predictions = predict(X, final_weights)
    plt.plot(x, predictions, color='blue', label='Fitted curve')
    
    plt.xlim(0, 10)
    plt.ylim(0, 20)

    plt.xticks(np.arange(0, 11, 1))
    plt.yticks(np.arange(0, 21, 2))
    
    plt.grid(True)
    
    plt.legend()
    plt.show()
    
    print("Weight history:")
    for epoch, w in enumerate(history):
        print(f"Epoch {epoch+1}: {w}")

if __name__ == '__main__':
    main()

